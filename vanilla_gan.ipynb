{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHJejx3duVzc"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nvqecpvzuVcl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCtqr7gHucJ-"
   },
   "source": [
    "# Setting cuda use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8m0JSP4cubxB"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "is_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGHQRtQawNqP"
   },
   "source": [
    "# Helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJhdVDkgwBJC"
   },
   "outputs": [],
   "source": [
    "def noise(x,y):\n",
    "    if is_cuda:\n",
    "        return torch.randn(x,y).cuda()\n",
    "    return torch.randn(x,y)\n",
    "\n",
    "def get_nearones(x):\n",
    "    if is_cuda:\n",
    "        return torch.ones(x,1).cuda()-0.01\n",
    "    return torch.ones(x,1)-0.01\n",
    "\n",
    "def get_nearzeros(x):\n",
    "    if is_cuda:\n",
    "        return torch.zeros(x,1).cuda()+0.01\n",
    "    return torch.zeros(x,1)+0.01\n",
    "\n",
    "def plotimage(is_cuda):\n",
    "    if is_cuda:\n",
    "        plt.imshow(generator(noise(1, 128)).cpu().detach().view(28,28).numpy(), cmap=cm.gray)\n",
    "    else:\n",
    "        plt.imshow(generator(noise(1, 128)).detach().view(28,28).numpy(), cmap=cm.gray)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5q8x2SlAubbC"
   },
   "source": [
    "# Getting training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "je2ARNKWvlQr"
   },
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor(), transforms.Normalize((.5,),(.5,)), torch.flatten])\n",
    "batches = 128\n",
    "\n",
    "traindata_path = './train'\n",
    "training_images = []\n",
    "for folder in os.listdir(traindata_path):\n",
    "    for image_name in os.listdir('{}/{}'.format(traindata_path, folder)):\n",
    "        image = Image.open('{}/{}/{}'.format(traindata_path, folder, image_name))\n",
    "        training_images.append(trans(image))\n",
    "        \n",
    "trainloader = torch.utils.data.DataLoader(training_images, batch_size=batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbWz_IlgtfmZ"
   },
   "source": [
    "# Create the Deep Fake Discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HS7MgVEJtcAU"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        ip_emb = 784\n",
    "        emb1 = 256\n",
    "        emb2 = 128\n",
    "        out_emb = 1\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "        nn.Linear(ip_emb, emb1),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Dropout(0.3))\n",
    "            \n",
    "        self.layer2 = nn.Sequential(\n",
    "        nn.Linear(emb1, emb2),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Dropout(0.3))\n",
    "        \n",
    "        self.layer_out = nn.Sequential(\n",
    "        nn.Linear(emb2, out_emb),\n",
    "        nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x\n",
    "\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClZEtjyutXAF"
   },
   "source": [
    "# Create the Deep Fake Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyzwMJi-tL2g"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        ip_emb = 128\n",
    "        emb1 = 256\n",
    "        emb2 = 512\n",
    "        emb3 = 1024\n",
    "        out_emb = 784\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "        nn.Linear(ip_emb, emb1),\n",
    "        nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "        nn.Linear(emb1, emb2),\n",
    "        nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "        nn.Linear(emb2, emb3),\n",
    "        nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.layer_out = nn.Sequential(\n",
    "        nn.Linear(emb3, out_emb),\n",
    "        nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x\n",
    "        \n",
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fwn4wCdvrpn"
   },
   "source": [
    "# Optimization criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUkPhmJ0vuRJ"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "discrim_optim = optim.Adam(discriminator.parameters(), lr= 0.0002)\n",
    "generat_optim = optim.Adam(generator.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVNf5sYDwYJ9"
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lRqgox3jiZEW"
   },
   "outputs": [],
   "source": [
    "if is_cuda:\n",
    "    discriminator.to(device)\n",
    "    generator.to(device)\n",
    "\n",
    "derrors = []\n",
    "gerrors = []\n",
    "dxcumul = []\n",
    "gxcumul = []\n",
    "\n",
    "for epoch in range(2000):\n",
    "    dx = 0\n",
    "    gx = 0\n",
    "    derr = 0\n",
    "    gerr = 0\n",
    "    for pos_samples in trainloader:\n",
    "        # Training Discriminator network\n",
    "        discrim_optim.zero_grad()\n",
    "        pos_sample = pos_samples[0].cuda() if is_cuda else pos_samples[0]\n",
    "        pos_predicted = discriminator(pos_sample)\n",
    "        pos_error = criterion(pos_predicted, get_nearones(batches))\n",
    "        \n",
    "        neg_samples = generator(noise(batches, 128))\n",
    "        neg_predicted = discriminator(neg_samples)\n",
    "        neg_error = criterion(neg_predicted, get_nearzeros(batches))\n",
    "        \n",
    "        discriminator_error = pos_error + neg_error\n",
    "        discriminator_error.backward()\n",
    "        discrim_optim.step()\n",
    "        \n",
    "        # Training generator network\n",
    "        generat_optim.zero_grad()\n",
    "        gen_samples = generator(noise(batches, 128))\n",
    "        gen_predicted = discriminator(gen_samples)\n",
    "        generator_error = criterion(gen_predicted, get_nearones(batches))\n",
    "        generator_error.backward()\n",
    "        generat_optim.step()\n",
    "        \n",
    "        derr += discriminator_error\n",
    "        gerr += generator_error\n",
    "        dx += pos_predicted.data.mean()\n",
    "        gx += neg_predicted.data.mean()\n",
    "        \n",
    "    print(f'Epoch:{epoch}.. D x : {dx/10:.4f}.. G x: {gx/10:.4f}.. D err : {derr/10:.4f}.. G err: {gerr/10:.4f}')\n",
    "    torch.save(discriminator, 'discriminator_model_vanilla_gan.pt')\n",
    "    torch.save(generator, 'generator_model_vanilla_gan.pt')\n",
    "    derrors.append(dx/10)\n",
    "    gerrors.append(gx/10)\n",
    "    if epoch %10 ==0:\n",
    "        plotimage(is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vo0jK6KZwsWq"
   },
   "source": [
    "# Plot errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhB0SDFywoix"
   },
   "outputs": [],
   "source": [
    "# Plotting the errors\n",
    "plt.plot(range(2000),[x.item() for x in derrors], color='r')\n",
    "plt.plot(range(2000),[y.item() for y in gerrors], color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uuM68RJw0PC"
   },
   "source": [
    "# Display generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSaIrd7owrmO"
   },
   "outputs": [],
   "source": [
    "# Images created by Generator network\n",
    "for i in range(10):\n",
    "    plotimage(is_cuda)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "VanillaGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
